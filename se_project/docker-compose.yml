services:
  # 메인 백엔드 서버
  backend:
    build:
      context: ./backend
      dockerfile: dockerfile
    ports:
      - "8003:8003"
    volumes:
      - ./data:/app/data
      - ./backend:/app
      - ./models/LLM:/app/models/LLM  
    depends_on:
      - vlm-server
    environment:
      - PYTHONPATH=/app
      - VLM_SERVER_URL=http://vlm-server:8001
      - OLLAMA_HOST=http://host.docker.internal:11434  
    extra_hosts:
      - "host.docker.internal:host-gateway"  
    networks:
      - recipe-network

  # VLM (Vision Language Model) 서버
  vlm-server:
    build:
      context: ./models/vlm_first
      dockerfile: dockerfile
    ports:
      - "8001:8001"
    volumes:
      - ./data:/app/data
      - ./models/vlm_first:/app
    environment:
      - PYTHONPATH=/app
      - OLLAMA_HOST=http://host.docker.internal:11434
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - recipe-network

  # LLM 서버 
  llm-server:
    build:
      context: ./models/LLM
      dockerfile: dockerfile
    ports:
      - "8002:8002"
    volumes:
      - ./data:/data
      - ./models/LLM:/app
    environment:
      - PYTHONPATH=/app
      - OLLAMA_HOST=http://host.docker.internal:11434
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - recipe-network

  # 프론트엔드 
  frontend:
    build:
      context: ./frontend
      dockerfile: dockerfile
    ports:
      - "3000:3000"
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
    environment:
      - REACT_APP_BACKEND_URL=http://localhost:8003
      - CHOKIDAR_USEPOLLING=true
    depends_on:
      - backend
    networks:
      - recipe-network

networks:
  recipe-network:
    driver: bridge

volumes:
  recipe-data:
